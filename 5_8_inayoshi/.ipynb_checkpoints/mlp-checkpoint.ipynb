{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron (MLP) の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. MNISTデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./')\n",
    "X, Y = mnist.data, mnist.target\n",
    "X = X / 255.\n",
    "Y = Y.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X[i * 6500].reshape(28, 28), cmap='gray_r')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "train_y = np.eye(10)[train_y].astype(np.int32)\n",
    "test_y = np.eye(10)[test_y].astype(np.int32)\n",
    "train_n = train_x.shape[0]\n",
    "test_n = test_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        exp_x = np.exp(x - x.max(axis=1, keepdims=True))\n",
    "        y = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        return y\n",
    "\n",
    "    def backward(self, x):\n",
    "        return self.x * (1 -  self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        self.y = y\n",
    "        return y\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return self.y * (1 -  self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __call__(self, x):\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return 1 * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, activation):\n",
    "        self.W = np.random.uniform(low=-0.08, high=0.08, size=(in_dim, out_dim))\n",
    "#         self.W = np.random.randn(in_dim, out_dim) * np.sqrt(2.0 / in_dim)  # Heの初期値\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.activation = activation()\n",
    "        self.delta = None\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.W) + self.b\n",
    "        self.z = self.activation(self.u)\n",
    "        return self.z\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.delta = dout * self.activation.backward(self.u)\n",
    "        \n",
    "        self.dW = np.dot(self.x.T, self.delta)\n",
    "        self.db = np.dot(np.ones(len(self.x)), self.delta)\n",
    "        \n",
    "        return np.dot(self.delta, self.W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def train(self, x, t, lr):     \n",
    "        # 1. 順伝播\n",
    "        self.y = x\n",
    "        for layer in self.layers:\n",
    "            self.y = layer(self.y)\n",
    "        self.loss = np.sum(-t*np.log(self.y + 1e-7)) / len(x)\n",
    "        \n",
    "        # 2. 誤差逆伝播\n",
    "        # 最終層の誤差\n",
    "#         delta = (self.y - t) / len(self.layers[-1].x)\n",
    "        delta = self.y - t\n",
    "        self.layers[-1].delta = delta\n",
    "        self.layers[-1].dW = np.dot(self.layers[-1].x.T, self.layers[-1].delta)\n",
    "        self.layers[-1].db = np.dot(np.ones(len(self.layers[-1].x)), self.layers[-1].delta)\n",
    "        dout = np.dot(self.layers[-1].delta, self.layers[-1].W.T)\n",
    "        \n",
    "        # 中間層の誤差を計算\n",
    "        for layer in self.layers[-2::-1]:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        # 3. 各層のパラメータを更新\n",
    "        for layer in self.layers:\n",
    "            layer.W -= lr * layer.dW\n",
    "            layer.b -= lr * layer.db\n",
    "            \n",
    "        return self.loss\n",
    "    \n",
    "    \n",
    "    def test(self, x, t):\n",
    "        # 順伝播 (train関数と全く同じでOK)\n",
    "        self.y = x\n",
    "        for layer in self.layers:\n",
    "            self.y = layer(self.y)\n",
    "        self.loss = np.sum(-t*np.log(self.y + 1e-7)) / len(x)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP([Linear(784, 1000, ReLU),\n",
    "                        Linear(1000, 1000, ReLU),\n",
    "                        Linear(1000, 10, Softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "batchsize = 100\n",
    "lr = 0.01\n",
    "\n",
    "losses = {'train':[], 'test': []}\n",
    "accuracies = {'train':[], 'test':[]}\n",
    "for epoch in range(n_epoch):\n",
    "    print('epoch %d |' % epoch,)\n",
    "    \n",
    "    # Training\n",
    "    sum_loss = 0\n",
    "    pred_y = []\n",
    "    perm = np.random.permutation(train_n)\n",
    "    \n",
    "    for i in range(0, train_n, batchsize):\n",
    "        x = train_x[perm[i:i+batchsize]]\n",
    "        t = train_y[perm[i:i+batchsize]]\n",
    "        \n",
    "        sum_loss += model.train(x, t, lr) * len(x)\n",
    "        pred_y.extend(np.argmax(model.y, axis=1))\n",
    "    \n",
    "    loss = sum_loss / train_n\n",
    "    losses['train'].append(loss)\n",
    "    accuracy = np.sum(np.eye(10)[pred_y] * train_y[perm]) / train_n\n",
    "    accuracies['train'].append(accuracy)\n",
    "    print('Train loss %.3f, accuracy %.4f |' %(loss, accuracy),)\n",
    "    \n",
    "    \n",
    "    # Testing\n",
    "    sum_loss = 0\n",
    "    pred_y = []\n",
    "    \n",
    "    for i in range(0, test_n, batchsize):\n",
    "        x = test_x[i: i+batchsize]\n",
    "        t = test_y[i: i+batchsize]\n",
    "        \n",
    "        sum_loss += model.test(x, t) * len(x)\n",
    "        pred_y.extend(np.argmax(model.y, axis=1))\n",
    "\n",
    "    loss = sum_loss / test_n\n",
    "    losses['test'].append(loss)\n",
    "    accuracy = np.sum(np.eye(10)[pred_y] * test_y) / test_n\n",
    "    accuracies['test'].append(accuracy)\n",
    "    print('Test loss %.3f, accuracy %.4f' %(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

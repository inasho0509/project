{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression ハンズオン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. softmax関数\n",
    "入力：$\\boldsymbol{X}=(\\boldsymbol{x_1},\\boldsymbol{x_2},\\cdots,\\boldsymbol{x_N})^T\\in\\mathbb{R}^{N\\times K}$（データ行列）\n",
    "\n",
    "出力：$\\boldsymbol{Y}=(\\boldsymbol{y_1},\\boldsymbol{y_2},\\cdots,\\boldsymbol{y_N})^T\\in\\mathbb{R}^{N\\times K},\\,\\,\\,y_{nk} = softmax(\\boldsymbol{x_n})_k$\n",
    "\n",
    "$$\n",
    "softmax(\\boldsymbol x)_k = \\frac{e^{x_{k}}} {\\Sigma_{i=1}^{K}{e^{x_{i}}}}\\\\\n",
    "$$\n",
    "オーバーフローを防ぐために$\\boldsymbol{x}_n$の最大値を$\\boldsymbol{x}_n$自身から引く\n",
    "$$\n",
    "\\begin{align}\n",
    "softmax(\\boldsymbol{x})_k&= \\frac{e^{x_{k}}} {\\Sigma_{i=1}^{K}{e^{x_{i}}}}=\\frac{e^{-x_{max}}e^{x_{k}}}{e^{-x_{max}}\\Sigma_{i=1}^{K}{e^{x_{i}}}}=\\frac{e^{(x_{k}-x_{max})}} {\\Sigma_{i=1}^{K}{e^{(x_{i}-x_{max})}}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - x.max(axis=1, keepdims=True))  # prevent overflow\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. cross entropy\n",
    "入力： $Y=(\\boldsymbol{y_1},\\boldsymbol{y_2},\\cdots,\\boldsymbol{y_N})^T\\in \\mathbb{R}^{N\\times K}$, \n",
    "$T=(\\boldsymbol{t_1},\\boldsymbol{t_2},\\cdots,\\boldsymbol{t_N})\\in \\mathbb{R}^{N\\times K} $\n",
    "\n",
    "($\\boldsymbol{y}_n$はソフトマックス関数の出力，$\\boldsymbol{t}_n$は教師ラベル）\n",
    "\n",
    "出力： $l=\\frac{1}{N}\\sum_{n=1}^Ncross\\_entropy(\\boldsymbol{y}_n,\\boldsymbol{t}_n)\\in\\mathbb{R}^1$\n",
    "$$\n",
    "cross\\_entropy(y, t)=\\sum_i t_i \\log(y_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, t):\n",
    "    return -np.mean(np.sum(t*np.log(y), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, t):\n",
    "    return np.mean(y==t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LogisticRegressionsクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配降下法: （$\\boldsymbol{W}：重み行列$）\n",
    "$$\n",
    "\\boldsymbol{W}\\leftarrow\\boldsymbol{W}-\\epsilon\\nabla_{\\boldsymbol{W}}J(\\boldsymbol{W})\\,\\,\\,(\\epsilon:学習率)\n",
    "$$\n",
    "ロジスティック回帰の勾配 :($\\boldsymbol{X}:データ行列,\\,\\,\\,\\boldsymbol{Y}：ロジスティック回帰による予測値,\\,\\,\\,\\boldsymbol{T}:正解ラベル$)\n",
    "$$\n",
    "\\nabla_{\\boldsymbol{W}}J(\\boldsymbol{W})=\\boldsymbol{X}^T(\\boldsymbol{Y}-\\boldsymbol{T})\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.W = np.random.uniform(0.08, -0.08, (n_in, n_out))\n",
    "        self.b = np.zeros(n_out)\n",
    "\n",
    "    def train(self, x, t, lr):\n",
    "        y = softmax(np.dot(x, self.W) + self.b)\n",
    "        delta = y - t\n",
    "        \n",
    "        self.W -= lr * np.dot(x.T, delta)\n",
    "        self.b -= lr * np.mean(delta, axis=0)\n",
    "        \n",
    "        loss = cross_entropy(y, t)\n",
    "        return y, loss\n",
    "\n",
    "    def test(self, x, t):\n",
    "        y = softmax(np.dot(x, self.W) + self.b)\n",
    "        loss = cross_entropy(y, t)\n",
    "        return y, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnistデータのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "X,T = mnist.data, mnist.target\n",
    "X = X / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e7a2898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X[i * 6500].reshape(28, 28), cmap='gray_r')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, T_train, T_test = train_test_split(X, T, test_size=0.2)\n",
    "N_train = X_train.shape[0]\n",
    "N_test = X_test.shape[0]\n",
    "T_train = T_train.astype(\"int\")\n",
    "T_test = T_test.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 |Train loss 0.433, accuracy 0.8782 |Test loss 0.374, accuracy 0.8918\n",
      "epoch 1 |Train loss 0.320, accuracy 0.9084 |Test loss 0.327, accuracy 0.9084\n",
      "epoch 2 |Train loss 0.310, accuracy 0.9133 |Test loss 0.329, accuracy 0.9034\n",
      "epoch 3 |Train loss 0.300, accuracy 0.9154 |Test loss 0.328, accuracy 0.9065\n",
      "epoch 4 |Train loss 0.296, accuracy 0.9172 |Test loss 0.311, accuracy 0.9113\n",
      "epoch 5 |Train loss 0.290, accuracy 0.9193 |Test loss 0.327, accuracy 0.9046\n",
      "epoch 6 |Train loss 0.289, accuracy 0.9196 |Test loss 0.314, accuracy 0.9121\n",
      "epoch 7 |Train loss 0.285, accuracy 0.9203 |Test loss 0.303, accuracy 0.9151\n",
      "epoch 8 |Train loss 0.283, accuracy 0.9209 |Test loss 0.308, accuracy 0.9141\n",
      "epoch 9 |Train loss 0.280, accuracy 0.9213 |Test loss 0.325, accuracy 0.9076\n",
      "epoch 10 |Train loss 0.279, accuracy 0.9229 |Test loss 0.320, accuracy 0.9124\n",
      "epoch 11 |Train loss 0.278, accuracy 0.9224 |Test loss 0.337, accuracy 0.9066\n",
      "epoch 12 |Train loss 0.277, accuracy 0.9231 |Test loss 0.329, accuracy 0.9044\n",
      "epoch 13 |Train loss 0.276, accuracy 0.9243 |Test loss 0.317, accuracy 0.9115\n",
      "epoch 14 |Train loss 0.275, accuracy 0.9224 |Test loss 0.315, accuracy 0.9118\n",
      "epoch 15 |Train loss 0.271, accuracy 0.9253 |Test loss 0.321, accuracy 0.9094\n",
      "epoch 16 |Train loss 0.270, accuracy 0.9247 |Test loss 0.312, accuracy 0.9154\n",
      "epoch 17 |Train loss 0.271, accuracy 0.9245 |Test loss 0.311, accuracy 0.9144\n",
      "epoch 18 |Train loss 0.270, accuracy 0.9253 |Test loss 0.315, accuracy 0.9134\n",
      "epoch 19 |Train loss 0.268, accuracy 0.9257 |Test loss 0.307, accuracy 0.9162\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 20\n",
    "batchsize = 100\n",
    "lr = 0.01\n",
    "\n",
    "model = LogisticRegression(784, 10)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print ('epoch %d |' % epoch, end=\"\")\n",
    "    \n",
    "    # Training\n",
    "    sum_loss = 0\n",
    "    pred_label = []\n",
    "    perm = np.random.permutation(N_train)\n",
    "    \n",
    "    for i in range(0, N_train, batchsize):\n",
    "        x = X_train[perm[i:i+batchsize]]\n",
    "        t = np.eye(10)[T_train[perm[i:i+batchsize]]]\n",
    "        \n",
    "        y, loss = model.train(x, t, lr)\n",
    "        sum_loss += loss * x.shape[0]\n",
    "        pred_label.extend(y.argmax(axis=1))\n",
    "    \n",
    "    loss = sum_loss / N_train\n",
    "    accu = accuracy(pred_label, T_train[perm])\n",
    "    print('Train loss %.3f, accuracy %.4f |' %(loss, accu), end=\"\")\n",
    "    \n",
    "    \n",
    "    # Testing\n",
    "    sum_loss = 0\n",
    "    pred_label = []\n",
    "    \n",
    "    for i in range(0, N_test, batchsize):\n",
    "        x = X_test[i: i+batchsize]\n",
    "        t = np.eye(10)[T_test[i: i+batchsize]]\n",
    "        \n",
    "        y, loss = model.test(x, t)\n",
    "        sum_loss += loss * x.shape[0]\n",
    "        pred_label.extend(y.argmax(axis=1))\n",
    "        \n",
    "    loss = sum_loss / N_test\n",
    "    accu = accuracy(pred_label, T_test)\n",
    "    print('Test loss %.3f, accuracy %.4f' %(loss, accu) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
